# src/ingest.py
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter  # Äá»•i import nÃ y
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
import os

# Cáº¥u hÃ¬nh
DATA_PATH = "crawl_data"
CHROMA_PATH = "chroma_db"
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

def load_documents():
    """Load táº¥t cáº£ file txt tá»« thÆ° má»¥c processed"""
    loader = DirectoryLoader(
        DATA_PATH,
        glob="**/*.txt",
        loader_cls=TextLoader,
        loader_kwargs={"encoding": "utf-8"}
    )
    documents = loader.load()
    print(f"âœ… ÄÃ£ load {len(documents)} documents")
    return documents

def split_documents(documents):
    """Chia documents thÃ nh chunks"""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
        separators=["\n\n", "\n", ".", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… ÄÃ£ chia thÃ nh {len(chunks)} chunks")
    return chunks

def create_vector_store(chunks):
    """Táº¡o ChromaDB tá»« chunks"""
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': 'cpu'}
    )
    
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=CHROMA_PATH
    )
    print(f"âœ… ÄÃ£ lÆ°u vÃ o ChromaDB táº¡i {CHROMA_PATH}")
    return vectorstore

def main():
    print("ğŸš€ Báº¯t Ä‘áº§u ingest dá»¯ liá»‡u...")
    
    # 1. Load documents
    documents = load_documents()
    
    # 2. Split thÃ nh chunks
    chunks = split_documents(documents)
    
    # 3. Táº¡o vector store
    vectorstore = create_vector_store(chunks)
    
    print("ğŸ‰ HoÃ n thÃ nh!")

if __name__ == "__main__":
    main()